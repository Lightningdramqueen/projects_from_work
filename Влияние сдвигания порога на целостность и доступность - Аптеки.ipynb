{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from connectors import read_sql_query\n",
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings()\n",
    "from typing import List, Optional, Tuple\n",
    "import sqlalchemy\n",
    "from urllib.parse import quote_plus\n",
    "from datetime import datetime,timedelta\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Озерки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "retailer = 333 #332 для доктора столетова\n",
    "start_date = '2024-09-17'\n",
    "end_date = '2024-09-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:33<00:00, 106.89s/it]\n"
     ]
    }
   ],
   "source": [
    "list_df = []\n",
    "for date in tqdm(pd.date_range(start=start_date, end=end_date)):\n",
    "    df = read_sql_query(f'''\n",
    "    with all_scores_cte as (\n",
    "    select\n",
    "        dt as datetime_score_update, --дата+время обновления скора\n",
    "        date(dt) as date_dt, --дата обновления скора\n",
    "        store_id, --ID магазина\n",
    "        retailer_id, --ID ритейлера\n",
    "        retailer_sku, --СКЮ ритейлера\n",
    "        round(cast(element_at(filter(data, x -> x.key = 'score'), 1)[2][1] as double),3) as score --собственно скор oos модели\n",
    "    from iceberg.dwh_raw_producthub.raw_stock_2 \n",
    "    where date(dt) between date('{date.strftime(\"%Y-%m-%d\")}') and date('{date.strftime(\"%Y-%m-%d\")}')\n",
    "    and ab_group = '' \n",
    "    and retailer_id = {retailer}\n",
    "    group by 1,2,3,4,5,6\n",
    "\n",
    "    )\n",
    "\n",
    "    select \n",
    "        retailer_sku, \n",
    "        retailer_id,  \n",
    "        store_id, \n",
    "        datetime_score_update,\n",
    "        date_dt,\n",
    "        score\n",
    "    from all_scores_cte\n",
    "    where score is not null \n",
    "                            ''', con = 'trino')\n",
    "    list_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#данные по метрикам целостности\n",
    "df_rc_data = read_sql_query(f'''\n",
    "with \n",
    "    damage_orders_items_cte as (\n",
    "    select \n",
    "        shipment_number,\n",
    "        sku,\n",
    "        retailer_sku,\n",
    "        sku_status,\n",
    "        is_replacement,\n",
    "        quantity,\n",
    "        found_quantity,\n",
    "        weight_added_items,\n",
    "        weight_deleted_items,\n",
    "        gmv_final\n",
    "    from sandbox.damage_orders_items \n",
    "    where dt BETWEEN toDate('{start_date}') AND toDate('{end_date}')\n",
    "    ),\n",
    "\n",
    "\n",
    "   line_items_stats_cte as (\n",
    "    select \n",
    "    shipment_number, \n",
    "    retailer_sku,\n",
    "    countIf(sku, is_replacement = 0 and quantity > 0 ) as initial_sku,\n",
    "    countIf(sku, sku_status in  ('replaced', 'cancelled')) as rc_count_sku,\n",
    "    countIf(sku, sku_status in ('cancelled'))  as canc_count_sku,\n",
    "    countIf(sku, sku_status in ('replaced'))  as repl_count_sku,\n",
    "    sumIf(quantity,  is_replacement = 0) as initial_items,\n",
    "    sumIf(found_quantity,  sku_status not in  ('replaced', 'cancelled')) as final_items,\n",
    "    sum(weight_added_items) as weight_added_items,\n",
    "    sum(weight_deleted_items) as weight_deleted_items,\n",
    "    sum(gmv_final) as gmv_final\n",
    "    from damage_orders_items_cte \n",
    "    group by 1,2\n",
    "    ),\n",
    "    \n",
    "    shipments_stats_cte as (\n",
    "    select \n",
    "    shipment_id as shipment_id, \n",
    "    shipment_number as shipment_number,\n",
    "    completed_at,\n",
    "    starts_at,\n",
    "    store_id as store_id,\n",
    "    store_name, \n",
    "    retailer_id,\n",
    "    retailer_name,\n",
    "    type_delivery\n",
    "    from analytics.bi_shipments_financial\n",
    "    where toDate(completed_at) BETWEEN toDate('{start_date}') AND toDate('{end_date}')\n",
    "    and shipment_state = 'shipped'\n",
    "    and retailer_id = {retailer}\n",
    "    )\n",
    "\n",
    "    select \n",
    "        toDate(starts_at) as starts_at_date,\n",
    "        shipment_id,\n",
    "        starts_at,\n",
    "        retailer_sku,\n",
    "        store_id,\n",
    "        store_name,\n",
    "        retailer_id,\n",
    "        retailer_name,\n",
    "        gmv_final,\n",
    "        ifNull(initial_sku, 0) as initial_sku, \n",
    "        ifNull(rc_count_sku, 0) as  rc_count_sku, \n",
    "        ifNull(canc_count_sku, 0) as  canc_count_sku, \n",
    "        ifNull(repl_count_sku, 0) as  repl_count_sku, \n",
    "        ifNull(initial_items, 0) as  initial_items,\n",
    "        ifNull(if(type_delivery = 'scan_pay_go', initial_items, final_items),0) as final_items, \n",
    "        ifNull(weight_added_items,0) as weight_added_items, --добавленное кол-во штук\n",
    "        ifNull(if(type_delivery = 'scan_pay_go', 0, weight_deleted_items),0) as weight_deleted_items, --удаленное кол-во штук\n",
    "        sum(initial_items) over(partition by shipment_number) as initial_items_sum, --сумма всех изначальных товаров\n",
    "        sum(weight_added_items) over(partition by shipment_number) as weight_added_items_sum, --сумма всех добавленных товаров в заказе\n",
    "        sum(weight_deleted_items) over(partition by shipment_number) as weight_deleted_items_sum --сумма всех удаленных товаров в заказе\n",
    "    from line_items_stats_cte \n",
    "    inner join shipments_stats_cte\n",
    "        on line_items_stats_cte.shipment_number = shipments_stats_cte.shipment_number\n",
    "                            ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores['datetime_score_update'] = df_scores['datetime_score_update'].apply(lambda x: str(x)[0:19])\n",
    "df_scores['datetime_score_update'] = pd.to_datetime(df_scores['datetime_score_update'])\n",
    "df_scores['date_dt'] = pd.to_datetime(df_scores['date_dt'], format='%Y-%m-%d')\n",
    "\n",
    "df_scores['retailer_sku'] = df_scores['retailer_sku'].astype('str')\n",
    "df_rc_data['retailer_sku'] = df_rc_data['retailer_sku'].astype('str')\n",
    "\n",
    "merged_df = df_rc_data.merge(df_scores, how = 'left', on = ['retailer_sku', 'store_id'])\n",
    "merged_df_f = merged_df[merged_df.score.notnull()].query('starts_at > datetime_score_update') #выбираем время, где время старта слота больше времени обновления скора\n",
    "merged_df_f = merged_df_f.drop(['retailer_id_x', 'retailer_id_y'], axis=1)\n",
    "\n",
    "#берем максимальное время из отфильтрованных ранее\n",
    "max_update = pd.DataFrame(merged_df_f.groupby(['retailer_sku', 'store_id', 'starts_at']).datetime_score_update.max()).reset_index()\n",
    "\n",
    "#отбираем те строки со скором, где время обновления скора равно максимальному ДО времени начала слота\n",
    "df_scores_final = merged_df_f.merge(max_update, how = 'left', on = ['retailer_sku', 'store_id', 'starts_at']) \\\n",
    "        .query('datetime_score_update_x == datetime_score_update_y')\\\n",
    "        .drop(['datetime_score_update_x'], axis=1) \\\n",
    "        .rename(columns={\"datetime_score_update_y\": \"datetime_score_update_fin\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.17 #выбираем порог, который установим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.051654560129137"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#текущие отмены/замены\n",
    "current_rc = df_scores_final.rc_count_sku.sum()/df_scores_final.initial_sku.sum()*100\n",
    "current_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3422818791946298"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Потенциальное улучшение отмен/замен\n",
    "df_scores_final['rc_count_sku_new'] = np.where((df_scores_final['score'] < 0.24) & (df_scores_final['score'] >= threshold), 0, df_scores_final['rc_count_sku'])\n",
    "a = df_scores_final.rc_count_sku_new.sum()/df_scores_final.initial_sku.sum()*100\n",
    "b = df_scores_final.rc_count_sku.sum()/df_scores_final.initial_sku.sum()*100\n",
    "new_rc = a/b*100-100\n",
    "new_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.728813559322035"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_rc + current_rc/100*new_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#снэпшоты с данными по доступности товарного ассортимента, 1 на одну дату, без изменений в течение дня\n",
    "availability_data = read_sql_query(f'''\n",
    "select \n",
    "\tretailer_sku, \n",
    "\tproduct_sku,\n",
    "\tretailer_id,\n",
    "\tstore_id,\n",
    "    case when published = true then 1 else 0 end as published,\n",
    "    published_reason,                            \n",
    "\tsnapshot_date\n",
    "from iceberg.dwh_ods_producthub.stocks_history \n",
    "where date(snapshot_date) between date('{start_date}') and date('{end_date}')\n",
    "and retailer_id = {retailer}\n",
    "                            ''', con = 'trino'\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_data['snapshot_date'] = pd.to_datetime(availability_data['snapshot_date'], format='%Y-%m-%d')\n",
    "availability_data['retailer_sku'] = availability_data['retailer_sku'].astype('str')\n",
    "\n",
    "merged_avail_df = availability_data.merge(df_scores, how = 'left', on = ['retailer_sku', 'store_id'])\n",
    "merged_avail_df = merged_avail_df[merged_avail_df.score.notnull()].query('snapshot_date >= date_dt') #отбираем строки, где дата обновления скора равна дате снэпшота \n",
    "merged_avail_df = merged_avail_df.drop(['retailer_id_x', 'retailer_id_y'], axis=1)\n",
    "\n",
    "#отбираем самый последний сток на дату (можно выбирать самый первый, и то, и то будет не до конца корректно, но нам нужно выбрать)\n",
    "max_update_avail = pd.DataFrame(merged_avail_df.groupby(['retailer_sku', 'store_id', 'snapshot_date']).datetime_score_update.max()).reset_index()\n",
    "\n",
    "#оставляем только те строки, где время обновления скора равно максимальному времени обновления скора в этот день\n",
    "avail_df_final = merged_avail_df.merge(max_update_avail, how = 'left', on = ['retailer_sku', 'store_id', 'snapshot_date']) \\\n",
    "        .query('datetime_score_update_x == datetime_score_update_y')\\\n",
    "        .drop(['datetime_score_update_x'], axis=1) \\\n",
    "        .rename(columns={\"datetime_score_update_y\": \"datetime_score_update_fin\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.63164866402904"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_avail = avail_df_final.published.sum()/avail_df_final.published.count()*100\n",
    "current_avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.978707827741488"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Потенциальное СНИЖЕНИЕ доступности\n",
    "avail_df_final['published_new'] = np.where((avail_df_final['score'] < 0.24) & (avail_df_final['score'] >= threshold) & (avail_df_final['published_reason'] == 'on-by-oos') \\\n",
    "                                            , 0, avail_df_final['published'])\n",
    "a = avail_df_final.published_new.sum()/avail_df_final.published.count()*100\n",
    "b = avail_df_final.published.sum()/avail_df_final.published.count()*100\n",
    "new_avail = a/b*100-100\n",
    "new_avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.7894846181611"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_avail_number = current_avail + current_avail/100*new_avail\n",
    "new_avail_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.842164045867946"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_avail_number - current_avail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доктор столетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "retailer = 332 #332 для доктора столетова\n",
    "threshold = 0.20 #выбираем порог, который установим\n",
    "start_date = '2024-09-16'\n",
    "end_date = '2024-09-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [06:51<00:00, 137.29s/it]\n"
     ]
    }
   ],
   "source": [
    "list_df = []\n",
    "for date in tqdm(pd.date_range(start=start_date, end=end_date)):\n",
    "    df = read_sql_query(f'''\n",
    "    with all_scores_cte as (\n",
    "    select\n",
    "        dt as datetime_score_update, --дата+время обновления скора\n",
    "        date(dt) as date_dt, --дата обновления скора\n",
    "        store_id, --ID магазина\n",
    "        retailer_id, --ID ритейлера\n",
    "        retailer_sku, --СКЮ ритейлера\n",
    "        round(cast(element_at(filter(data, x -> x.key = 'score'), 1)[2][1] as double),3) as score --собственно скор oos модели\n",
    "    from iceberg.dwh_raw_producthub.raw_stock_2 \n",
    "    where date(dt) between date('{date.strftime(\"%Y-%m-%d\")}') and date('{date.strftime(\"%Y-%m-%d\")}')\n",
    "    and ab_group = '' \n",
    "    and retailer_id = {retailer}\n",
    "    group by 1,2,3,4,5,6\n",
    "\n",
    "    )\n",
    "\n",
    "    select \n",
    "        retailer_sku, \n",
    "        retailer_id,  \n",
    "        store_id, \n",
    "        datetime_score_update,\n",
    "        date_dt,\n",
    "        score\n",
    "    from all_scores_cte\n",
    "    where score is not null \n",
    "                            ''', con = 'trino')\n",
    "    list_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#данные по метрикам целостности\n",
    "df_rc_data = read_sql_query(f'''\n",
    "with \n",
    "    damage_orders_items_cte as (\n",
    "    select \n",
    "        shipment_number,\n",
    "        sku,\n",
    "        retailer_sku,\n",
    "        sku_status,\n",
    "        is_replacement,\n",
    "        quantity,\n",
    "        found_quantity,\n",
    "        weight_added_items,\n",
    "        weight_deleted_items,\n",
    "        gmv_final\n",
    "    from sandbox.damage_orders_items \n",
    "    where dt BETWEEN toDate('{start_date}') AND toDate('{end_date}')\n",
    "    ),\n",
    "\n",
    "\n",
    "   line_items_stats_cte as (\n",
    "    select \n",
    "    shipment_number, \n",
    "    retailer_sku,\n",
    "    countIf(sku, is_replacement = 0 and quantity > 0 ) as initial_sku,\n",
    "    countIf(sku, sku_status in  ('replaced', 'cancelled')) as rc_count_sku,\n",
    "    countIf(sku, sku_status in ('cancelled'))  as canc_count_sku,\n",
    "    countIf(sku, sku_status in ('replaced'))  as repl_count_sku,\n",
    "    sumIf(quantity,  is_replacement = 0) as initial_items,\n",
    "    sumIf(found_quantity,  sku_status not in  ('replaced', 'cancelled')) as final_items,\n",
    "    sum(weight_added_items) as weight_added_items,\n",
    "    sum(weight_deleted_items) as weight_deleted_items,\n",
    "    sum(gmv_final) as gmv_final\n",
    "    from damage_orders_items_cte \n",
    "    group by 1,2\n",
    "    ),\n",
    "    \n",
    "    shipments_stats_cte as (\n",
    "    select \n",
    "    shipment_id as shipment_id, \n",
    "    shipment_number as shipment_number,\n",
    "    completed_at,\n",
    "    starts_at,\n",
    "    store_id as store_id,\n",
    "    store_name, \n",
    "    retailer_id,\n",
    "    retailer_name,\n",
    "    type_delivery\n",
    "    from analytics.bi_shipments_financial\n",
    "    where toDate(completed_at) BETWEEN toDate('{start_date}') AND toDate('{end_date}')\n",
    "    and shipment_state = 'shipped'\n",
    "    and retailer_id = {retailer}\n",
    "    )\n",
    "\n",
    "    select \n",
    "        toDate(starts_at) as starts_at_date,\n",
    "        shipment_id,\n",
    "        starts_at,\n",
    "        retailer_sku,\n",
    "        store_id,\n",
    "        store_name,\n",
    "        retailer_id,\n",
    "        retailer_name,\n",
    "        gmv_final,\n",
    "        ifNull(initial_sku, 0) as initial_sku, \n",
    "        ifNull(rc_count_sku, 0) as  rc_count_sku, \n",
    "        ifNull(canc_count_sku, 0) as  canc_count_sku, \n",
    "        ifNull(repl_count_sku, 0) as  repl_count_sku, \n",
    "        ifNull(initial_items, 0) as  initial_items,\n",
    "        ifNull(if(type_delivery = 'scan_pay_go', initial_items, final_items),0) as final_items, \n",
    "        ifNull(weight_added_items,0) as weight_added_items, --добавленное кол-во штук\n",
    "        ifNull(if(type_delivery = 'scan_pay_go', 0, weight_deleted_items),0) as weight_deleted_items, --удаленное кол-во штук\n",
    "        sum(initial_items) over(partition by shipment_number) as initial_items_sum, --сумма всех изначальных товаров\n",
    "        sum(weight_added_items) over(partition by shipment_number) as weight_added_items_sum, --сумма всех добавленных товаров в заказе\n",
    "        sum(weight_deleted_items) over(partition by shipment_number) as weight_deleted_items_sum --сумма всех удаленных товаров в заказе\n",
    "    from line_items_stats_cte \n",
    "    inner join shipments_stats_cte\n",
    "        on line_items_stats_cte.shipment_number = shipments_stats_cte.shipment_number\n",
    "                            ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores['datetime_score_update'] = df_scores['datetime_score_update'].apply(lambda x: str(x)[0:19])\n",
    "df_scores['datetime_score_update'] = pd.to_datetime(df_scores['datetime_score_update'])\n",
    "df_scores['date_dt'] = pd.to_datetime(df_scores['date_dt'], format='%Y-%m-%d')\n",
    "\n",
    "df_scores['retailer_sku'] = df_scores['retailer_sku'].astype('str')\n",
    "df_rc_data['retailer_sku'] = df_rc_data['retailer_sku'].astype('str')\n",
    "\n",
    "merged_df = df_rc_data.merge(df_scores, how = 'left', on = ['retailer_sku', 'store_id'])\n",
    "merged_df_f = merged_df[merged_df.score.notnull()].query('starts_at > datetime_score_update') #выбираем время, где время старта слота больше времени обновления скора\n",
    "merged_df_f = merged_df_f.drop(['retailer_id_x', 'retailer_id_y'], axis=1)\n",
    "\n",
    "#берем максимальное время из отфильтрованных ранее\n",
    "max_update = pd.DataFrame(merged_df_f.groupby(['retailer_sku', 'store_id', 'starts_at']).datetime_score_update.max()).reset_index()\n",
    "\n",
    "#отбираем те строки со скором, где время обновления скора равно максимальному ДО времени начала слота\n",
    "df_scores_final = merged_df_f.merge(max_update, how = 'left', on = ['retailer_sku', 'store_id', 'starts_at']) \\\n",
    "        .query('datetime_score_update_x == datetime_score_update_y')\\\n",
    "        .drop(['datetime_score_update_x'], axis=1) \\\n",
    "        .rename(columns={\"datetime_score_update_y\": \"datetime_score_update_fin\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.17 #выбираем порог, который установим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.005545286506468"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#текущие отмены/замены\n",
    "current_rc = df_scores_final.rc_count_sku.sum()/df_scores_final.initial_sku.sum()*100\n",
    "current_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.15217391304347"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Потенциальное улучшение отмен/замен\n",
    "df_scores_final['rc_count_sku_new'] = np.where((df_scores_final['score'] < 0.24) & (df_scores_final['score'] >= threshold), 0, df_scores_final['rc_count_sku'])\n",
    "a = df_scores_final.rc_count_sku_new.sum()/df_scores_final.initial_sku.sum()*100\n",
    "b = df_scores_final.rc_count_sku.sum()/df_scores_final.initial_sku.sum()*100\n",
    "new_rc = a/b*100-100\n",
    "new_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.13995943204868"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_rc + current_rc/100*new_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#снэпшоты с данными по доступности товарного ассортимента, 1 на одну дату, без изменений в течение дня\n",
    "availability_data = read_sql_query(f'''\n",
    "select \n",
    "\tretailer_sku, \n",
    "\tproduct_sku,\n",
    "\tretailer_id,\n",
    "\tstore_id,\n",
    "    case when published = true then 1 else 0 end as published,\n",
    "    published_reason,                            \n",
    "\tsnapshot_date\n",
    "from iceberg.dwh_ods_producthub.stocks_history \n",
    "where date(snapshot_date) between date('{start_date}') and date('{end_date}')\n",
    "and retailer_id = {retailer}\n",
    "                            ''', con = 'trino'\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_data['snapshot_date'] = pd.to_datetime(availability_data['snapshot_date'], format='%Y-%m-%d')\n",
    "availability_data['retailer_sku'] = availability_data['retailer_sku'].astype('str')\n",
    "\n",
    "merged_avail_df = availability_data.merge(df_scores, how = 'left', on = ['retailer_sku', 'store_id'])\n",
    "merged_avail_df = merged_avail_df[merged_avail_df.score.notnull()].query('snapshot_date >= date_dt') #отбираем строки, где дата обновления скора равна дате снэпшота \n",
    "merged_avail_df = merged_avail_df.drop(['retailer_id_x', 'retailer_id_y'], axis=1)\n",
    "\n",
    "#отбираем самый последний сток на дату (можно выбирать самый первый, и то, и то будет не до конца корректно, но нам нужно выбрать)\n",
    "max_update_avail = pd.DataFrame(merged_avail_df.groupby(['retailer_sku', 'store_id', 'snapshot_date']).datetime_score_update.max()).reset_index()\n",
    "\n",
    "#оставляем только те строки, где время обновления скора равно максимальному времени обновления скора в этот день\n",
    "avail_df_final = merged_avail_df.merge(max_update_avail, how = 'left', on = ['retailer_sku', 'store_id', 'snapshot_date']) \\\n",
    "        .query('datetime_score_update_x == datetime_score_update_y')\\\n",
    "        .drop(['datetime_score_update_x'], axis=1) \\\n",
    "        .rename(columns={\"datetime_score_update_y\": \"datetime_score_update_fin\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.94917042066848"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_avail = avail_df_final.published.sum()/avail_df_final.published.count()*100\n",
    "current_avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.172566957113418"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Потенциальное СНИЖЕНИЕ доступности\n",
    "avail_df_final['published_new'] = np.where((avail_df_final['score'] < 0.24) & (avail_df_final['score'] >= threshold) & (avail_df_final['published_reason'] == 'on-by-oos') \\\n",
    "                                            , 0, avail_df_final['published'])\n",
    "a = avail_df_final.published_new.sum()/avail_df_final.published.count()*100\n",
    "b = avail_df_final.published.sum()/avail_df_final.published.count()*100\n",
    "new_avail = a/b*100-100\n",
    "new_avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.88349980611771"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_avail_number = current_avail + current_avail/100*new_avail\n",
    "new_avail_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.065670614550768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_avail_number - current_avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
